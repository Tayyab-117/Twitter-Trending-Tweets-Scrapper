{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grave-campus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\armag\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "from langdetect import detect\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capable-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = '7JlnkfQYVgs1x1mnMvm6nkOCc'\n",
    "consumer_secret = 'O99q9aa2kgKOo4ps1MNy4uJQx06VLOPjzKN6SxrJixNi1jNPgG'\n",
    "access_token = '520058445-WwG5wY1UIoMThSldZ0JY3DoKyPcHXv3X1pNxr86h'\n",
    "access_token_secret = '4OUVn4kTqKvDXEAF4YYiNd0wLZqRT5Ti7TPUJJvxGWou8'\n",
    "selected_language = 'ar'\n",
    "location = r'YOUR_LOCATION' ######LOCATION THAT YOU WANT TO SAVE CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infectious-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bottom-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(location):\n",
    "    df = pd.DataFrame()\n",
    "    df.to_csv(location, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crazy-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking all the WOEID codes of Countries\n",
    "woeid_list = []\n",
    "for val in api.trends_available():\n",
    "    if val['placeType']['name'] == 'Country':#if you want to extract more tweet change 'Country' to 'Town', but execution time will increase.\n",
    "        woeid_list.append(val['woeid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "radical-vitamin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(woeid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifteen-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_lists = []\n",
    "count_down = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "streaming-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting all the trends and appending to the list\n",
    "for woeid in woeid_list:\n",
    "    trends = api.trends_place(woeid)\n",
    "    all_tweet_lists.append(trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "binary-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_trends = {\n",
    "    'Name':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "peaceful-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweet_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "explicit-evans",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6129032258064515\n",
      "3.225806451612903\n",
      "4.838709677419355\n",
      "6.451612903225806\n",
      "8.064516129032258\n",
      "9.67741935483871\n",
      "11.29032258064516\n",
      "12.903225806451612\n",
      "14.516129032258066\n",
      "16.129032258064516\n",
      "17.741935483870968\n",
      "19.35483870967742\n",
      "20.967741935483872\n",
      "22.58064516129032\n",
      "24.193548387096776\n",
      "25.806451612903224\n",
      "27.419354838709676\n",
      "29.03225806451613\n",
      "30.64516129032258\n",
      "32.25806451612903\n",
      "33.87096774193548\n",
      "35.483870967741936\n",
      "37.096774193548384\n",
      "38.70967741935484\n",
      "40.32258064516129\n",
      "41.935483870967744\n",
      "43.54838709677419\n",
      "45.16129032258064\n",
      "46.774193548387096\n",
      "48.38709677419355\n",
      "50.0\n",
      "51.61290322580645\n",
      "53.2258064516129\n",
      "54.83870967741935\n",
      "56.451612903225815\n",
      "58.06451612903226\n",
      "59.67741935483871\n",
      "61.29032258064516\n",
      "62.903225806451616\n",
      "64.51612903225806\n",
      "66.12903225806451\n",
      "67.74193548387096\n",
      "69.35483870967742\n",
      "70.96774193548387\n",
      "72.58064516129032\n",
      "74.19354838709677\n",
      "75.80645161290323\n",
      "This text is passed because of NULL value.\n",
      "77.41935483870968\n",
      "79.03225806451613\n",
      "80.64516129032258\n",
      "82.25806451612904\n",
      "83.87096774193549\n",
      "85.48387096774194\n",
      "87.09677419354838\n",
      "88.70967741935483\n",
      "90.32258064516128\n",
      "91.93548387096774\n",
      "93.54838709677419\n",
      "95.16129032258065\n",
      "This text is passed because of NULL value.\n",
      "96.7741935483871\n",
      "98.38709677419355\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "#Appending arabic tweets to the twitter_trends['Name']\n",
    "count=0\n",
    "for tweet in all_tweet_lists:\n",
    "    for value in tweet:\n",
    "        for trend in value['trends']:\n",
    "            try:\n",
    "                if detect(trend['name']) == selected_language: #detecting language\n",
    "                    twitter_trends['Name'].append(trend['name'])\n",
    "            except:\n",
    "                print('This text is passed because of NULL value.')\n",
    "\n",
    "    count += 1\n",
    "    print(count/len(all_tweet_lists)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numeric-hunter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_trends['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "featured-lyric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit_per_trend = 900//len(twitter_trends['Name'])\n",
    "limit_per_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "floppy-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_output = {\n",
    "    'trend_name': [],\n",
    "    'trend_tweet': []\n",
    "}\n",
    "temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trend in twitter_trends['Name']:     \n",
    "    for tweet in tweepy.Cursor(api.search, q=trend, count=100000, lang=selected_language, since=date.today(),result_type='popular').items(limit_per_trend):\n",
    "        tweets_output['trend_name'].append(trend)\n",
    "        temp.append(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in temp:\n",
    "    a = a.replace('\\n', \"\")\n",
    "    tweets_output['trend_tweet'].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(location)\n",
    "df = pd.DataFrame(tweets_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([data, df], ignore_index=True).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(location, mode='a', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-savings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_gpu",
   "language": "python",
   "name": "new_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
